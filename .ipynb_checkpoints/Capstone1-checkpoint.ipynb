{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from drug_categories import dcat\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import patsy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Read the medications file\n",
    "med_file = \"PartD_Prescriber_PUF_NPI_Drug_15.txt.gz\"\n",
    "dfx = pd.read_csv(med_file, delimiter=\"\\t\")\n",
    "\n",
    "# Create a variable indicating which drugs are opioids\n",
    "dfx[\"opioid\"] = dfx.drug_name.isin(dcat[\"opioid\"])\n",
    "\n",
    "# Get the total day supply for each provider, for opioids and non-opioids\n",
    "dr = dfx.groupby([\"npi\", \"opioid\"]).agg({\"total_day_supply\": np.sum})\n",
    "dr = dr.unstack()\n",
    "dr = dr.rename(columns={False: \"Non_opioids\", True: \"Opioids\"})\n",
    "dr = dr.fillna(0)\n",
    "dr = dr.reset_index()\n",
    "dr.columns = [\"npi\", \"Non_opioids\", \"Opioids\"]\n",
    "\n",
    "# Merge in the state where the provider operates\n",
    "ds = dfx.groupby(\"npi\").agg({'nppes_provider_state': \"first\", \"nppes_provider_city\": \"first\"})\n",
    "ds = ds.reset_index()\n",
    "dr = pd.merge(dr, ds, left_on=\"npi\", right_on=\"npi\")\n",
    "dr = dr.rename(columns={\"nppes_provider_state\": \"state\", \"nppes_provider_city\": \"city\"})\n",
    "\n",
    "# Drop providers who never prescribe opioids, or who never prescribe any drugs.\n",
    "dr = dr.loc[dr.Opioids > 0, :]\n",
    "dr = dr.loc[dr.Non_opioids > 0, :]\n",
    "\n",
    "# Remove very small states\n",
    "s = dr.groupby(\"state\").size()\n",
    "s = pd.DataFrame({\"num_providers\": s})\n",
    "dr = pd.merge(dr, s, left_on=\"state\", right_index=True, how='left')\n",
    "dr = dr.loc[dr.num_providers >= 500]\n",
    "\n",
    "# Create log transformed variables and z-scores\n",
    "dr[\"log_op\"] = np.log2(0.1 + dr.Opioids)\n",
    "dr[\"log_nonop\"] = np.log2(0.1 + dr.Non_opioids)\n",
    "dr[\"log_op_z\"] = (dr.log_op - dr.log_op.mean()) / dr.log_op.std()\n",
    "dr[\"log_nonop_z\"] = (dr.log_nonop - dr.log_nonop.mean()) / dr.log_nonop.std()\n",
    "\n",
    "dr = dr.dropna()\n",
    "\n",
    "pdf = PdfPages(\"opioids.pdf\")\n",
    "\n",
    "# Plot overall log/log data\n",
    "plt.clf()\n",
    "plt.plot(dr.log_op, dr.log_nonop, 'o', color='orange', alpha=0.3, rasterized=True)\n",
    "plt.xlabel(\"Non-opioid days supply\")\n",
    "plt.ylabel(\"Opioids days supply\")\n",
    "plt.grid(True)\n",
    "pdf.savefig()\n",
    "\n",
    "# Basic log/log regression model, looking at how overall prescribing\n",
    "# predicts opioid prescribing\n",
    "olsmodel = sm.OLS.from_formula(\"log_op ~ log_nonop\", data=dr)\n",
    "olsresult = olsmodel.fit()\n",
    "olsmodelz = sm.OLS.from_formula(\"log_op_z ~ log_nonop_z\", data=dr)\n",
    "olsresultz = olsmodelz.fit()\n",
    "\n",
    "# Fit log opioid versus non-opioid volume separately by state\n",
    "plt.clf()\n",
    "bxr = np.linspace(-4, 4, 20)\n",
    "for sn, dz in dr.groupby(\"state\"):\n",
    "    # sn is the state's name, dz is the data for that state\n",
    "    model = sm.OLS.from_formula(\"log_op_z ~ log_nonop_z\", data=dz)\n",
    "    result = model.fit()\n",
    "    params = result.params.values\n",
    "    plt.plot(bxr, params[0] + params[1]*bxr, '-', color='grey')\n",
    "plt.title(\"Trends by state\")\n",
    "plt.xlabel(\"Log non-opioid days supply (Z-score)\")\n",
    "plt.ylabel(\"Log opioid days supply (Z-score)\")\n",
    "pdf.savefig()\n",
    "\n",
    "pdf.close()\n",
    "\n",
    "# Fit three different fixed effects models for opioid volume relative to non-opioid volume.\n",
    "\n",
    "# Allow the intercepts to vary by state (no z-scoring)\n",
    "femodel = sm.OLS.from_formula(\"log_op ~ log_nonop + C(state)\", data=dr)\n",
    "feresult = femodel.fit()\n",
    "\n",
    "# Allow the intercepts to vary by state (with z-scoring)\n",
    "femodelz = sm.OLS.from_formula(\"log_op_z ~ log_nonop_z + C(state)\", data=dr)\n",
    "feresultz = femodelz.fit()\n",
    "\n",
    "# Allow the slopes and intercepts to vary by state (with z-scoring)\n",
    "femodelsz = sm.OLS.from_formula(\"log_op_z ~ log_nonop_z * C(state)\", data=dr)\n",
    "feresultsz = femodelsz.fit()\n",
    "\n",
    "# Pairwise comparison of state intercepts, for every pair of states.\n",
    "# It's important here to use centered (or Z-scored) data here so the\n",
    "# intercepts are inside the range of the data.\n",
    "\n",
    "pa = feresultz.params # Parameter estimates\n",
    "vc = feresultz.cov_params() # Covariance matrix of parameter estimates\n",
    "\n",
    "# Positions of the state fixed effects in the parameter vector\n",
    "ii = [i for i,x in enumerate(pa.index) if x.startswith(\"C(state\")]\n",
    "\n",
    "# Reduce the parameter estimate vector and covariance matrix to contain\n",
    "# only the parameters corresponding to state effects\n",
    "pa = pa.iloc[ii]\n",
    "vc = vc.iloc[ii, ii]\n",
    "\n",
    "# Get the contrast for every pair of states\n",
    "zc = np.zeros((len(pa), len(pa)))\n",
    "for i1 in range(len(pa)):\n",
    "    for i2 in range(len(pa)):\n",
    "\n",
    "        # Create a contrast vector between states i1 and i2\n",
    "        d = np.zeros(len(pa))\n",
    "        d[i1] = 1\n",
    "        d[i2] = -1\n",
    "\n",
    "        # Get the contrast and standard error (for comparing these two states)\n",
    "        se = np.sqrt(np.dot(d, np.dot(vc, d)))\n",
    "        zc[i1, i2] = (pa[i1] - pa[i2]) / se\n",
    "\n",
    "# Put the results in a dataframe with columns showing the two states\n",
    "# being compared, and the Z-score for the difference of the state interepts\n",
    "j1, j2 = np.tril_indices(len(pa), -1) # The lower triangle so we don't repeat pairs\n",
    "statepair_icept_z = pd.DataFrame({\"State1\": pa.index.values[j1],\n",
    "                                  \"State2\": pa.index.values[j2],\n",
    "                                  \"Diff\": zc[j1, j2]})\n",
    "statepair_icept_z = statepair_icept_z.sort_values(by=\"Diff\")\n",
    "\n",
    "# Pairwise comparison of state slopes, for every pair of states\n",
    "# See preceeding section, the code is very simuilar except here we\n",
    "# work with the slope parameters instead of the intercept parameters\n",
    "\n",
    "pa = feresultsz.params # All parameter estimates\n",
    "vc = feresultsz.cov_params() # Covariance matrix for all parameter estiamtes\n",
    "\n",
    "# Restrict to only the slope parameter estimates\n",
    "ii = [i for i,x in enumerate(pa.index) if x.startswith(\"log_nonop_z:C(state\")]\n",
    "pa = pa.iloc[ii]\n",
    "vc = vc.iloc[ii, ii]\n",
    "\n",
    "zcx = np.zeros((len(pa), len(pa)))\n",
    "for i1 in range(len(pa)):\n",
    "    for i2 in range(len(pa)):\n",
    "\n",
    "        # Contrast vector\n",
    "        d = np.zeros(len(pa))\n",
    "        d[i1] = 1\n",
    "        d[i2] = -1\n",
    "\n",
    "        # Standard error of the contrast\n",
    "        se = np.sqrt(np.dot(d, np.dot(vc, d)))\n",
    "\n",
    "        # Z-score of the contrast\n",
    "        zcx[i1, i2] = (pa[i1] - pa[i2]) / se\n",
    "\n",
    "j1, j2 = np.tril_indices(len(pa), -1)\n",
    "statepair_slope_z = pd.DataFrame({\"State1\": pa.index.values[j1],\n",
    "                                  \"State2\": pa.index.values[j2],\n",
    "                                  \"Diff\": zcx[j1, j2]})\n",
    "statepair_slope_z = statepair_slope_z.sort_values(by=\"Diff\")\n",
    "\n",
    "# Mean/variance analysis for basic model\n",
    "dr[\"fit\"] = olsresult.fittedvalues\n",
    "dr[\"bin\"] = pd.qcut(dr.fit, 20) # Slice the fitted values into 20 bins\n",
    "meanvar_base = dr.groupby(\"bin\")[\"fit\", \"log_op\"].agg({\"fit\": np.mean, \"log_op\": np.var})\n",
    "meanvar_base = meanvar_base.rename(columns={\"fit\": \"mean\", \"log_op\": \"var\"})\n",
    "\n",
    "# Mean/variance analysis for state-adjusted model\n",
    "dr[\"fit\"] = feresult.fittedvalues\n",
    "dr[\"bin\"] = pd.qcut(dr.fit, 20) # Slice the fitted values into 20 bins\n",
    "meanvar_states = dr.groupby(\"bin\")[\"fit\", \"log_op\"].agg({\"fit\": np.mean, \"log_op\": np.var})\n",
    "meanvar_states = meanvar_states.rename(columns={\"fit\": \"mean\", \"log_op\": \"var\"})\n",
    "\n",
    "# Basic mixed model with intercepts that vary by state (\"random intercepts\")\n",
    "memodel_i = sm.MixedLM.from_formula(\"log_op_z ~ log_nonop_z\", groups=\"state\", data=dr)\n",
    "meresult_i = memodel_i.fit()\n",
    "\n",
    "# Mixed model with slopes that vary by state (\"random slopes\")\n",
    "memodel_is = sm.MixedLM.from_formula(\"log_op_z ~ log_nonop_z\", groups=\"state\",\n",
    "                                     vc_formula={\"i\": \"0 + C(state)\", \"s\": \"0+log_nonop_z:C(state)\"},\n",
    "                                     data=dr)\n",
    "meresult_is = memodel_is.fit()\n",
    "\n",
    "# Basic mixed model for cities (random intercepts by city)\n",
    "# too slow to run\n",
    "#memodel_c = sm.MixedLM.from_formula(\"log_op_z ~ log_nonop_z\", groups=\"city\", data=dr)\n",
    "#meresult_c = memodel_c.fit()\n",
    "\n",
    "db = pd.read_csv(\"2015_utilization_reduced.csv.gz\")\n",
    "\n",
    "# Merge provider type\n",
    "du = db.groupby(\"npi\")[\"provider_type\"].agg(\"first\")\n",
    "du = pd.DataFrame(du).reset_index()\n",
    "dr = pd.merge(dr, du, left_on=\"npi\", right_on=\"npi\")\n",
    "\n",
    "# Use LARS to consider provider type effects.  LARS can't accept a formula, so we\n",
    "# construct the response vector and design matrix outside of LARS then pass them\n",
    "# in.\n",
    "y, x = patsy.dmatrices(\"log_op_z ~ 0 + log_nonop_z + C(provider_type)\", data=dr,\n",
    "                       return_type='dataframe')\n",
    "\n",
    "# Standardize\n",
    "xa = np.asarray(x)\n",
    "xa -= xa.mean(0)\n",
    "xa /= xa.std(0)\n",
    "ya = np.asarray(y)[:, 0]\n",
    "ya -= ya.mean(0)\n",
    "ya /= ya.std(0)\n",
    "xnames = x.columns.tolist()\n",
    "\n",
    "# Run LARS\n",
    "alphas, active, coefs = linear_model.lars_path(xa, ya, method='lars', verbose=True)\n",
    "coefs = coefs[:, 1:] # coefs starts with an extra column of zeros\n",
    "\n",
    "# Display the first few variables selected by LARS and the correlation\n",
    "# between fitted and observed values\n",
    "for k in range(20):\n",
    "\n",
    "    # k denotes the order in which the variables are added to the model\n",
    "    # by LARS.  active[k-1] contains the indicators of the variables in\n",
    "    # the model at stage k\n",
    "\n",
    "    # Print the variables in the order they are selected, and the correlation\n",
    "    # coefficients between these fitted values and the observed outcomes.\n",
    "    f = np.dot(xa, coefs[:, k])\n",
    "    print(\"%-60s %6.2f %8.4f\" % (xnames[active[k]],\n",
    "                                 np.corrcoef(ya, f)[0, 1],\n",
    "                                 coefs[active[k], k]))\n",
    "\n",
    "# Fixed effects model for provider type\n",
    "pfemodelz = sm.OLS.from_formula(\"log_op_z ~ log_nonop_z + C(provider_type)\",\n",
    "                                data=dr)\n",
    "pferesultz = pfemodelz.fit()\n",
    "\n",
    "# Basic mixed model (random intercepts by provider)\n",
    "pmemodelz = sm.MixedLM.from_formula(\"log_op_z ~ log_nonop_z\", groups=\"provider_type\", data=dr)\n",
    "pmeresultz = pmemodelz.fit()\n",
    "\n",
    "# Merge the BLUPs with the fixed effects estimates\n",
    "re = pmeresultz.random_effects\n",
    "re = {k: re[k].provider_type for k in re.keys()}\n",
    "re = pd.DataFrame({\"re\": pd.Series(re)})\n",
    "fe = {}\n",
    "for k in pferesultz.params.index:\n",
    "    if k != \"Intercept\" and k != \"log_nonop_z\":\n",
    "        v = k.replace(\"C(provider_type)[T.\", \"\")\n",
    "        v = v[0:-1]\n",
    "        fe[v] = pferesultz.params[k]\n",
    "fe = pd.Series(fe)\n",
    "fe = pd.DataFrame(fe, columns=[\"fe\"])\n",
    "refe = pd.merge(fe, re, left_index=True, right_index=True)\n",
    "\n",
    "# Mean center to eliminate dependence on the reference category\n",
    "refe -= refe.mean(0)\n",
    "\n",
    "# Add in the sample size (per group) so we can see how this relates\n",
    "# to the degree of shrinkage\n",
    "n = dr.provider_type.value_counts()\n",
    "n = pd.DataFrame(n)\n",
    "n.columns=[\"n\"]\n",
    "refe = pd.merge(refe, n, left_index=True, right_index=True)\n",
    "\n",
    "# Mixed model looking at provider types: allow varying intercepts and slopes\n",
    "# by provider type\n",
    "pmemodels = sm.MixedLM.from_formula(\"log_op_z ~ log_nonop_z\", groups=\"provider_type\",\n",
    "                                    vc_formula={\"i\": \"0+C(provider_type)\",\n",
    "                                                \"s\": \"0+log_nonop_z:C(provider_type)\"},\n",
    "                                    data=dr)\n",
    "pmeresults = pmemodels.fit()\n",
    "\n",
    "# Use LARS to consider provider effects and state effects together\n",
    "y, x = patsy.dmatrices(\"log_op_z ~ 0 + log_nonop_z + C(provider_type) + C(state)\", data=dr,\n",
    "                       return_type='dataframe')\n",
    "\n",
    "# Standardize\n",
    "xa = np.asarray(x)\n",
    "xa -= xa.mean(0)\n",
    "xa /= xa.std(0)\n",
    "ya = np.asarray(y)[:,0]\n",
    "ya -= ya.mean(0)\n",
    "ya /= ya.std(0)\n",
    "xnames = x.columns.tolist()\n",
    "\n",
    "# Run LARS for provider and state varying intercepts\n",
    "alphas, active, coefs = linear_model.lars_path(xa, ya, method='lars', verbose=True)\n",
    "coefs = coefs[:, 1:]\n",
    "\n",
    "# Display the first few variables selected by LARS, and the correlations between\n",
    "# fitted and observed values for each model selected by LARS.\n",
    "print(\"\\nLARS path for provider type and state main effects:\")\n",
    "for k in range(20):\n",
    "    f = np.dot(xa, coefs[:, k])\n",
    "    print(\"%-60s %6.2f %8.4f\" % (xnames[active[k]],\n",
    "                                 np.corrcoef(ya, f)[0, 1],\n",
    "                                 coefs[active[k], k]))\n",
    "\n",
    "if noproc:\n",
    "    import sys\n",
    "    sys.exit(0)\n",
    "\n",
    "#\n",
    "# Procedure type analysis\n",
    "#\n",
    "\n",
    "# Count the number of times each provider performs each procedure type\n",
    "du = db.groupby([\"npi\", \"hcpcs_code\"])[\"line_srvc_cnt\"].agg(np.sum)\n",
    "du = du.unstack(fill_value=0)\n",
    "\n",
    "# Use SVD to form composite variables of the procedure data\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=50, n_iter=7, random_state=42)\n",
    "xr = svd.fit_transform(du.values)\n",
    "xr = pd.DataFrame(xr, index=du.index)\n",
    "xr.columns = [\"proc_%02d\" % k for k in range(xr.shape[1])]\n",
    "\n",
    "# Remove any existing 'proc' variables from dr so we can merge in the new proc composite\n",
    "# variables\n",
    "for c in dr.columns:\n",
    "    if c.startswith(\"proc\"):\n",
    "        dr = dr.drop(c, axis=1)\n",
    "dr = pd.merge(dr, xr, left_on=\"npi\", right_index=True)\n",
    "\n",
    "# Use LARS to get the solution path for procedure types\n",
    "procs = \" + \".join(xr.columns.tolist())\n",
    "y, x = patsy.dmatrices(\"log_op_z ~ 0 + log_nonop_z + %s\" % procs,\n",
    "                       data=dr, return_type='dataframe')\n",
    "\n",
    "# Standardize the data before running LARS on it\n",
    "xa = np.asarray(x)\n",
    "ya = np.asarray(y)[:,0]\n",
    "xa -= xa.mean(0)\n",
    "xa /= xa.std(0)\n",
    "ya -= ya.mean()\n",
    "ya /= ya.std()\n",
    "xnames = x.columns.tolist()\n",
    "\n",
    "# Run LARS on procedure type factors\n",
    "alphas, active, coefs = linear_model.lars_path(xa, ya, method='lars', verbose=True)\n",
    "\n",
    "# Display the first few variables selected by LARS, and the\n",
    "# correlations between fitted and observed values at each step.\n",
    "print(\"\\nLARS path for procedure types:\")\n",
    "for k in range(1, 10):\n",
    "    print(xnames[active[k-1]])\n",
    "    f = np.dot(xa, coefs[:, k])\n",
    "    print(k, np.corrcoef(ya, f)[0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
